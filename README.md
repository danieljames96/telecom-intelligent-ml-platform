# Intelligent Telecom Operations & Optimization Platform

This project builds an end-to-end big data ML system tailored for the telecom industry. It integrates:

- ğŸ“ˆ **Time Series Forecasting** for traffic/load per cell tower
- ğŸ›‘ **Anomaly Detection** to flag unusual activity or failures
- ğŸ” **Recommender Systems** for churn prevention and plan upgrades
- ğŸ”— **Graph ML** for analyzing the telecom network graph
- ğŸ§  **Variational Autoencoders (VAE)** for generative modeling & anomaly scoring
- âš¡ **PySpark** to handle large-scale data processing of CDRs and network logs

## ğŸš€ Features
- Forecast regional traffic using LSTM/TFT
- Detect anomalies using Autoencoders and Isolation Forests
- Train GNNs to model device-user networks
- Generate recommendations using Spark ALS or hybrid models
- Build a live dashboard with Streamlit

## ğŸ§° Tech Stack
- Python, PySpark, Pandas, Scikit-learn
- PyTorch, PyTorch Lightning, PyTorch Geometric
- MLlib, Streamlit, NetworkX, Neo4j
- Jupyter, YAML for config

## ğŸ“ Folder Structure

telecom-intelligent-platform/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original or simulated CDRs, traffic logs, etc.
â”‚   â”œâ”€â”€ processed/             # Cleaned, transformed datasets
â”‚   â””â”€â”€ external/              # Any downloaded public datasets
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for exploration & prototyping
â”‚   â”œâ”€â”€ eda/
â”‚   â”œâ”€â”€ forecasting/
â”‚   â”œâ”€â”€ anomaly_detection/
â”‚   â””â”€â”€ graph_modeling/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingestion/        # PySpark ETL jobs
â”‚   â”‚   â”œâ”€â”€ load_cdrs.py
â”‚   â”‚   â”œâ”€â”€ transform_logs.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ forecasting/           # Time series forecasting models
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”‚
â”‚   â”œâ”€â”€ anomaly_detection/     # VAE, Isolation Forests, etc.
â”‚   â”‚   â”œâ”€â”€ train_vae.py
â”‚   â”‚   â”œâ”€â”€ detect_anomalies.py
â”‚   â”‚   â””â”€â”€ evaluate.py
â”‚   â”‚
â”‚   â”œâ”€â”€ recommender/           # PySpark ALS, hybrid recommenders
â”‚   â”‚   â”œâ”€â”€ train_als.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ graph_ml/              # Graph construction & GNN models
â”‚   â”‚   â”œâ”€â”€ build_graph.py
â”‚   â”‚   â”œâ”€â”€ gnn_model.py
â”‚   â”‚   â””â”€â”€ train_gnn.py
â”‚   â”‚
â”‚   â””â”€â”€ vae_module/            # Shared VAE models for anomaly & gen
â”‚       â”œâ”€â”€ vae.py
â”‚       â””â”€â”€ train.py
â”‚
â”œâ”€â”€ dashboard/                 # Streamlit or Dash app
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ components/
â”‚
â”œâ”€â”€ config/                    # Config files (YAML/JSON) for pipeline params
â”‚   â”œâ”€â”€ spark_config.yaml
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ dashboard_config.yaml
â”‚
â”œâ”€â”€ scripts/                   # Bash or Python scripts for running jobs
â”‚   â”œâ”€â”€ run_pipeline.sh
â”‚   â””â”€â”€ launch_dashboard.sh
â”‚
â”œâ”€â”€ tests/                     # Unit and integration tests
â”‚   â”œâ”€â”€ test_forecasting.py
â”‚   â”œâ”€â”€ test_recommender.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt           # Python + PySpark dependencies
â”œâ”€â”€ environment.yml            # Conda environment (if using)
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

## ğŸ“Š **Project Data Plan**

| **Module**                | **Dataset Needed**                                                     | **Source**                          | **Purpose**                                                      |
|---------------------------|------------------------------------------------------------------------|-------------------------------------|------------------------------------------------------------------|
| **1. Time Series Forecasting** | Telecom traffic volume by region/tower/time                             | âœ… Synthetic (generated) or ğŸ“¦ OpenCelliD + simulated usage | Predict traffic spikes, enable pre-scaling of resources         |
| **2. Anomaly Detection**      | Sensor logs / usage logs with anomalies                                  | âœ… Synthetic with injected anomalies | Detect performance drops, network failures                      |
| **3. Graph ML**               | Device â†” User â†” Tower relationships (telecom graph)                      | âœ… Synthetic or ğŸ“¦ MIT Reality Mining / D4D | Model failure propagation, optimize network topology            |
| **4. Recommender System**     | Customer usage history, plan info, churn flags                           | ğŸ“¦ IBM Telecom Churn Dataset or âœ… Simulated | Recommend upgrades, predict churn                               |
| **5. VAE Module**             | Normal network behavior logs or encoded traffic sequences                | Derived from anomaly dataset        | Learn compressed latent space, generate synthetic behavior data |
| **6. PySpark Ingestion**      | Raw CDRs (Call Detail Records), usage logs, support ticket logs          | âœ… Simulated or ğŸ“¦ D4D / Alibaba traces | Handle large-scale ingestion, cleaning, transformations         |
| **7. Dashboard**              | Combined data outputs (forecasts, anomalies, graphs, recs)               | Internal project outputs            | Visualization & interaction with the system                     |

## Usage

1. Clone the repository
2. Generate the data using the script scripts/generate_data.py
3. Place the [IBM Telco Churn](https://www.kaggle.com/datasets/yeanzc/telco-customer-churn-ibm-dataset) Kaggle dataset under data/external
4. Run the script scripts/process_all_data.py using the Docker container.
docker compose build
docker compose up
docker-compose exec pyspark-notebook python work/scripts/process_all_data.py

docker exec -it telecom-intelligent-ml-platform-pyspark-notebook-1 bash